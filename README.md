# 🧠 Data Lakehouse de Vendas com Azure e PySpark

Este projeto simula uma arquitetura de *Data Lakehouse* para ingestão, transformação e análise de dados de vendas, com foco em *ambientes industriais e de supply chain. Ele foi desenvolvido como parte do meu portfólio para demonstrar habilidades em **engenharia de dados aplicada à Indústria 4.0, usando **Azure, Python e PySpark*.

## 🎯 Objetivo

Modelar e implantar um pipeline moderno para ingestão de dados de vendas, simulando cenários reais da cadeia de suprimentos, produção e operações industriais.

## ⚙️ Tecnologias e Ferramentas

- ☁️ *Azure Data Lake Storage*  
- 🔍 *Azure Synapse Analytics*
- 🐍 *Python 3.x*
- 🔥 *Apache Spark com PySpark*
- 🧱 *Parquet / CSV*
- 🧪 *Pipelines de dados (simulados)*
- 🧠 *Git e GitHub*

## 📁 Estrutura do Projeto

- projeto_dados_csv.zip: contém os dados brutos utilizados no pipeline.
- scripts/: (serão adicionados) scripts de transformação com PySpark.
- notebooks/: (em breve) notebooks de análise de dados e validação.

## 📌 Escopo e Progresso

- [x] Upload dos dados brutos
- [ ] Ingestão no Data Lake (simulado com pastas locais/Blobs)
- [ ] Transformações PySpark (normalização, limpeza, enriquecimento)
- [ ] Armazenamento otimizado (Parquet em camada Silver/Gold)
- [ ] Análises e KPIs industriais (produção, vendas, lead time)
- [ ] Integração futura com Power BI ou Synapse Studio

## 🏭 Aplicações práticas

- Previsão de demanda de vendas por filial ou SKU
- Identificação de gargalos na cadeia logística
- Otimização de tempo de resposta de pedidos (order-to-delivery)
- Criação de dashboards industriais em tempo real

## 👤 Autor

*Jones Neto*  
Engenheiro de Dados em formação | Experiência na indústria siderúrgica e farmacêutica  
Foco em soluções para *Indústria 4.0, **Supply Chain Digital* e *HealthTech*  
🔗 [LinkedIn](https://www.linkedin.com/in/seulinkedin)  
🌍 Brasil | Buscando oportunidades globais

📌 Este projeto está em desenvolvimento contínuo. Feedbacks são bem-vindos!
